{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "slowfast_stage1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sStCNsSYisN8dd-C-4yeIfw0TfQK-xvF",
      "authorship_tag": "ABX9TyMiio/TfDhwaKmHXa3YSqAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanhao1998/AutoDL-Projects/blob/main/slowfast_stage1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate the stage 1 of our imagined slowfast system:\n",
        "- Different models have different view space. And, combing these models together leads to a big vew space.\n",
        "- A routing model help find the suitable model processing the images."
      ],
      "metadata": {
        "id": "F14McOEU7iB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "\n",
        "Needs to be executed once in every VM.\n",
        "\n",
        "The cell below downloads the code from Github and install necessary dependencies."
      ],
      "metadata": {
        "id": "N_YvpreP-ZEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')\n",
        "# root = '/gdrive/My Drive/slowfast_system/stage1'\n",
        "# root = '/gdrive/My Drive/vision_transformer_colab'\n",
        "# import os\n",
        "# if not os.path.isdir(root):\n",
        "#   os.mkdir(root)\n",
        "# os.chdir(root)\n",
        "# print(f'\\nChanged CWD to \"{root}\"')\n",
        "\n",
        "root = 'drive/MyDrive/slowfast_system/stage1'"
      ],
      "metadata": {
        "id": "pESvFVWKe8bq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository and pull latest changes.\n",
        "# ![ -d slowfast_system] || git clone https://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@github.com/tanhao1998/slowfast_system.git\n",
        "# !cd slowfast_system && git pull"
      ],
      "metadata": {
        "id": "0pjJe9zPsEEr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18SVTu2XsBQd",
        "outputId": "b170d0b8-43a5-47ff-b606-da1cac809f3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ptflops in /usr/local/lib/python3.7/dist-packages (0.6.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops) (3.10.0.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "_31KF-IwwEIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ze17BSVCsK03"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "JrzVlxNGsObB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "w4350zo5x7B7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'cifar10'\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "precrop = 224\n",
        "\n",
        "train_tx = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((precrop, precrop)),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "val_tx = tv.transforms.Compose([\n",
        "    tv.transforms.Resize((precrop, precrop)),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "N3z4Te4gysMq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = tv.datasets.CIFAR10('./data', transform=train_tx, train=True, download=True)\n",
        "testset = tv.datasets.CIFAR10('./data', transform=val_tx, train=False, download=True)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size, shuffle=False,\n",
        "    num_workers=2, pin_memory=True, drop_last=False)\n",
        "\n",
        "# loader_valid = torch.utils.data.DataLoader(\n",
        "#     valid_set, batch_size=batch_size, shuffle=False,\n",
        "#     num_workers=16, pin_memory=True, drop_last=False)\n",
        "\n",
        "# order = sorted(range(len(train_set.targets)), key=lambda k: train_set.targets[k])\n",
        "# order_val = sorted(range(len(valid_set.targets)), key=lambda k: valid_set.targets[k])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qDp494fx-ri",
        "outputId": "81a856e1-64ae-4fc8-fb3c-dfdeff4d4bbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Boilerplate"
      ],
      "metadata": {
        "id": "TBH8oh8RwQgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "metadata": {
        "id": "3oWJhdzcwSgA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stairs(s, v, *svs):\n",
        "    \"\"\" Implements a typical \"stairs\" schedule for learning-rates.\n",
        "    Best explained by example:\n",
        "    stairs(s, 0.1, 10, 0.01, 20, 0.001)\n",
        "    will return 0.1 if s<10, 0.01 if 10<=s<20, and 0.001 if 20<=s\n",
        "    \"\"\"\n",
        "    for s0, v0 in zip(svs[::2], svs[1::2]):\n",
        "        if s < s0:\n",
        "            break\n",
        "        v = v0\n",
        "    return v\n",
        "\n",
        "def rampup(s, peak_s, peak_lr):\n",
        "  if s < peak_s:  # Warmup\n",
        "    return s/peak_s * peak_lr\n",
        "  else:\n",
        "    return peak_lr\n",
        "\n",
        "# def schedule(s):\n",
        "#   step_lr = stairs(s, 3e-3, 200, 3e-4, 300, 3e-5, 400, 3e-6, 500, None)\n",
        "#   return rampup(s, 100, step_lr)"
      ],
      "metadata": {
        "id": "KKSS2zXQwV16"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune"
      ],
      "metadata": {
        "id": "nTVZTkF91NV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "crit = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "\n",
        "def init_model(name='vit_tiny_patch16_224'):\n",
        "  model = timm.create_model(name, pretrained=True, num_classes=num_classes)\n",
        "  model = torch.nn.DataParallel(model)\n",
        "\n",
        "  # Note: no weight-decay!\n",
        "  optim = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "  model = model.to(device)\n",
        "  optim.zero_grad()\n",
        "\n",
        "  return model.train(), optim"
      ],
      "metadata": {
        "id": "G5pBCBXW1slW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_cifar10(model, dataset, bs=100, progressbar=True):\n",
        "  loader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=False, num_workers=2)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  if progressbar is True:\n",
        "    progressbar = display(progress(0, len(loader)), display_id=True)\n",
        "\n",
        "  preds = []\n",
        "  with torch.no_grad():\n",
        "    for i, (x, t) in enumerate(loader):\n",
        "      x, t = x.to(device), t.numpy()\n",
        "      logits = model(x)\n",
        "      _, y = torch.max(logits.data, 1)\n",
        "      preds.extend(y.cpu().numpy() == t)\n",
        "      progressbar.update(progress(i+1, len(loader)))\n",
        "\n",
        "  return np.mean(preds), preds"
      ],
      "metadata": {
        "id": "iL6IiwVXotQr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import join as pjoin  # pylint: disable=g-importing-member\n",
        "\n",
        "S = 500\n",
        "def schedule(s):\n",
        "  step_lr = stairs(s, 3e-3, 200, 3e-4, 300, 3e-5, 400, 3e-6, S, None)\n",
        "  return rampup(s, 100, step_lr)\n",
        "\n",
        "\n",
        "def train(model, optim, name=\"fast\"):\n",
        "  pb_train = display(progress(0, S), display_id=True)\n",
        "  pb_test = display(progress(0, 100), display_id=True)\n",
        "  losses = [[]]\n",
        "  accus_train = [[]]\n",
        "  accus_test = []\n",
        "\n",
        "  steps_per_iter = 512 // loader_train.batch_size\n",
        "\n",
        "  while len(losses) < S:\n",
        "    for x, t in loader_train:\n",
        "      x, t = x.to(device), t.to(device)\n",
        "      logits = model(x)\n",
        "      loss = crit(logits, t) / steps_per_iter\n",
        "      loss.backward()\n",
        "      losses[-1].append(loss.item())\n",
        "\n",
        "      with torch.no_grad():\n",
        "        accus_train[-1].extend(torch.max(logits, dim=1)[1].cpu().numpy() == t.cpu().numpy())\n",
        "\n",
        "      if len(losses[-1]) == steps_per_iter:\n",
        "        losses[-1] = sum(losses[-1])\n",
        "        losses.append([])\n",
        "        accus_train[-1] = np.mean(accus_train[-1])\n",
        "        accus_train.append([])\n",
        "\n",
        "        # Update learning-rate according to schedule, and stop if necessary\n",
        "        lr = schedule(len(losses) - 1)\n",
        "        for param_group in optim.param_groups:\n",
        "          param_group['lr'] = lr\n",
        "\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "\n",
        "        pb_train.update(progress(len(losses) - 1, S))\n",
        "        print(f'\\r[Step {len(losses) - 1}] loss={losses[-2]:.2e} '\n",
        "              f'train accu={accus_train[-2]:.2%} '\n",
        "              f'test accu={accus_test[-1] if accus_test else 0:.2%} '\n",
        "              f'(lr={lr:g})', end='', flush=True)\n",
        "\n",
        "        if len(losses) % 25 == 0:\n",
        "          accus_test.append(eval_cifar10(model, testset, progressbar=pb_test)[0])\n",
        "          model.train()\n",
        "\n",
        "          savename = pjoin(root, name + str(len(losses)-1) + \".pth.tar\")\n",
        "          torch.save({\n",
        "                          \"step\": len(losses) - 1,\n",
        "                          \"losses\": losses,\n",
        "                          \"model\": model.state_dict(),\n",
        "                          \"optim\": optim.state_dict(),\n",
        "                      }, savename)\n"
      ],
      "metadata": {
        "id": "Hhg5WwZVgrav"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "s_model, s_optim = init_model('vit_tiny_patch16_224')\n",
        "macs, params = get_model_complexity_info(s_model, (3, 224, 224), as_strings=True,\n",
        "                                        print_per_layer_stat=False, verbose=True)\n",
        "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
        "\n",
        "\n",
        "losses, accus_train, accus_test = train(s_model, s_optim, name=\"slow\")\n",
        "\n",
        "# fmodel = timm.create_model('tf_mobilenetv3_small_100', pretrained=True, num_classes=num_classes)\n",
        "# fmodel = torch.nn.DataParallel(fmodel)\n",
        "\n",
        "\n",
        "# from pprint import pprint\n",
        "# model_names = timm.list_models('*vit*')\n",
        "# pprint(model_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "2heH9pxY5IEz",
        "outputId": "4abc8219-9bbe-4514-9eb4-f742c80c47b7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module Identity is treated as a zero-op.\n",
            "Warning: module PatchEmbed is treated as a zero-op.\n",
            "Warning: module Dropout is treated as a zero-op.\n",
            "Warning: module LayerNorm is treated as a zero-op.\n",
            "Warning: module Attention is treated as a zero-op.\n",
            "Warning: module GELU is treated as a zero-op.\n",
            "Warning: module Mlp is treated as a zero-op.\n",
            "Warning: module Block is treated as a zero-op.\n",
            "Warning: module VisionTransformer is treated as a zero-op.\n",
            "Warning: module DataParallel is treated as a zero-op.\n",
            "Computational complexity:       1.07 GMac\n",
            "Number of parameters:           5.53 M  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='362'\n",
              "            max='500',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            362\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='100'\n",
              "            max='100',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            100\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Step 362] loss=3.15e-02 train accu=99.22% test accu=97.11% (lr=3e-05)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-fcf038af59f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccus_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccus_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"slow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# fmodel = timm.create_model('tf_mobilenetv3_small_100', pretrained=True, num_classes=num_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-c450223a3b1c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optim, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps_per_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = [[]]\n",
        "accus_train = [[]]\n",
        "accus_test = []\n",
        "\n",
        "steps_per_iter = 512 // loader_train.batch_size\n",
        "print('steps_per_iter:', steps_per_iter)\n",
        "\n",
        "for x, t in loader_train:\n",
        "  print(x.shape, t.shape)\n",
        "  x, t = x.to(device), t.to(device)\n",
        "\n",
        "  logits = s_model(x)\n",
        "  loss = crit(logits, t) / steps_per_iter\n",
        "  print(loss)\n",
        "  # del x, t\n",
        "  break\n",
        "  loss.backward()\n",
        "  losses[-1].append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C00ThjWQz93K",
        "outputId": "1c2cf124-7411-49aa-cfbb-bc11fbff57a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps_per_iter: 4\n",
            "torch.Size([128, 3, 224, 224]) torch.Size([128])\n",
            "tensor(0.6829, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(loss.item())\n",
        "# crit(logits, t)\n",
        "losses[-1].append(loss.item())"
      ],
      "metadata": {
        "id": "06awf-nS3ff0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(losses[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuAiGzyt4Kk1",
        "outputId": "c8aedb26-a322-41b8-dd03-637e7a39a23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(losses, accus_train, accus_test):\n",
        "  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
        "  ax1.plot(losses[:-1])\n",
        "  ax1.set_yscale('log')\n",
        "  ax1.set_title('loss')\n",
        "  ax2.plot(accus_train[:-1])\n",
        "  ax2.set_title('training accuracy')\n",
        "  ax3.plot(np.arange(25, 501, 25), accus_test)\n",
        "  ax3.set_title('test accuracy');"
      ],
      "metadata": {
        "id": "wPO-JdSlgrvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training(losses, accus_train, accus_test)"
      ],
      "metadata": {
        "id": "ud_Rk-vx6mmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find indices to create a sorted CIFAR10 variant\n"
      ],
      "metadata": {
        "id": "a14wpiF3rV7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Figure\n",
        "x_scale = 50\n",
        "y_scale = 50\n",
        "\n",
        "# Sample the dataset\n",
        "\n",
        "preprocess_tiny = tv.transforms.Compose([tv.transforms.CenterCrop((2, 2)), tv.transforms.ToTensor()])\n",
        "trainset_tiny = tv.datasets.CIFAR10(root='./data', train=True, download=False, transform=preprocess_tiny)\n",
        "loader = torch.utils.data.DataLoader(trainset_tiny, batch_size=50000, shuffle=False, num_workers=2)\n",
        "images, labels = iter(loader).next()"
      ],
      "metadata": {
        "id": "2NlynqNbrXSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = {cls: np.random.choice(np.where(labels.numpy() == cls)[0], 250, replace=False) for cls in range(10)}"
      ],
      "metadata": {
        "id": "SA4a_Wqfs5Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "cnt = 0\n",
        "for label in indices.keys():\n",
        "  for image in indices[label]:\n",
        "      data.append([cnt // y_scale, cnt % y_scale, trainset_tiny.classes[label])\n",
        "      cnt += 1"
      ],
      "metadata": {
        "id": "Y_ryINmSttwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data,columns=['index i','index j', 'classes'])\n",
        "\n",
        "\n",
        "fig =  px.scatter(df, x = 'index i', y = 'index j', color='classes', range_x=[-0.5, x_scale-0.5],range_y=[-0.5, y_scale-0.5], title='subtraining set on CIFAR10')\n",
        "fig.update_traces(marker=dict(size=6, symbol='square'))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "n5cEzL-1yOme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sort = torch.utils.data.Subset(trainset, indices=[i for v in indices.values() for i in v])\n",
        "len(train_sort)"
      ],
      "metadata": {
        "id": "4Y3hoDH6tPp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the model"
      ],
      "metadata": {
        "id": "LAnYrFPoyhy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = eval_cifar10(model, train_sort)[1]\n",
        "\n",
        "reg_preds = []\n",
        "for i in range(x_scale*y_scale):\n",
        "  reg_preds.append([cnt // y_scale, cnt % y_scale, preds[i])\n"
      ],
      "metadata": {
        "id": "gHub3mwuyjQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data,columns=['index i','index j', 'prediction'])\n",
        "\n",
        "\n",
        "fig =  px.scatter(df, x = 'index i', y = 'index j', color='classes', range_x=[-0.5, x_scale-0.5],range_y=[-0.5, y_scale-0.5], title='prediction on subtraining set of CIFAR10')\n",
        "fig.update_traces(marker=dict(size=6, symbol='square'))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EvSLU01RzI_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UazfYG89y6Pq",
        "outputId": "9a20d99b-aec9-4b92-fa74-17f7f40d21d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 13 23:20:35 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    62W / 149W |   5976MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'drive/MyDrive/slowfast_system/stage1'"
      ],
      "metadata": {
        "id": "dm1kO1kR2A3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/slowfast_system/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIgk0yxF2gvp",
        "outputId": "6e5f5b3f-3275-46ee-c9c9-cd27fef16186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stage1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNet.from_pretrained(‘efficientnet-b0’)\n",
        "device = torch.device(“cuda”)\n",
        "model.to(device)\n",
        "dummy_input = torch.randn(optimal_batch_size, 3,224,224, dtype=torch.float).to(device)\n",
        "repetitions=100\n",
        "total_time = 0\n",
        "with torch.no_grad():\n",
        "  for rep in range(repetitions):\n",
        "     starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "     starter.record()\n",
        "     _ = model(dummy_input)\n",
        "     ender.record()\n",
        "     torch.cuda.synchronize()\n",
        "     curr_time = starter.elapsed_time(ender)/1000\n",
        "     total_time += curr_time\n",
        "Throughput = (repetitions*optimal_batch_size)/total_time\n",
        "print(‘Final Throughput:’,Throughput)"
      ],
      "metadata": {
        "id": "LxRs90yZ5irK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}